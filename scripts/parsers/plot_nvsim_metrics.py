#!/usr/bin/env python3
import argparse
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime
import os
import numpy as np
import warnings

def parse_timestamp(timestamp):
    """Parse timestamp from NVSIM log format"""
    try:
        return datetime.strptime(timestamp, '%Y%m%d-%H:%M:%S')
    except ValueError:
        try:
            return datetime.strptime(timestamp, '%Y%m%d-%H:%M:%S.%f')
        except ValueError:
            return None

def read_nvsim_metrics(csv_file):
    """Read CSV files generated by parse_nvsim_log.py"""
    # Read CSV file, skip comments starting with #
    with open(csv_file, 'r') as f:
        comments = []
        for line in f:
            if line.startswith('#'):
                comments.append(line.strip('# \n'))
            else:
                break

    # Read data section
    df = pd.read_csv(csv_file, comment='#')

    # Convert Timestamp column to datetime objects
    if 'Timestamp' in df.columns:
        df['Timestamp'] = df['Timestamp'].apply(parse_timestamp)

    # Convert non-numeric fields (like "N/A") to NaN
    for col in df.columns:
        if col != 'Timestamp' and col not in ['ProductName', 'Architecture', 'PerfState']:
            df[col] = pd.to_numeric(df[col], errors='coerce')

    return df, comments

def calculate_stable_mean(values, stability_window=5, stability_threshold=0.10):
    """
    Calculate the mean value during the stable period of a metric.

    Args:
        values: List of numeric values
        stability_window: Window size to check for stability (number of consecutive points)
        stability_threshold: Maximum allowed relative change within window to be considered stable

    Returns:
        Mean value during the stable period or None if no stable period found
    """
    if not isinstance(values, np.ndarray):
        values = np.array(values)

    # Filter NaN values
    values = values[~np.isnan(values)]

    if len(values) < stability_window * 2:
        return None

    # Find maximum value to identify potential stable periods
    max_value = np.max(values)
    max_index = np.argmax(values)

    # Look for stable period around maximum value
    stable_start = max_index
    stable_end = max_index

    # Search backward from max_index to find start of stable period
    for i in range(max_index, 0, -1):
        if abs(values[i] - values[i-1]) / max(values[i], 1) > stability_threshold:
            stable_start = i
            break

    # Search forward from max_index to find end of stable period
    for i in range(max_index, len(values)-1):
        if abs(values[i] - values[i+1]) / max(values[i], 1) > stability_threshold:
            stable_end = i
            break

    # If the stable period is too short, try to find the longest stable period
    if stable_end - stable_start < stability_window:
        best_stable_len = 0
        best_stable_start = 0
        best_stable_end = 0

        i = 0
        while i < len(values) - 1:
            j = i + 1
            while j < len(values) and abs(values[j] - values[j-1]) / max(values[j-1], 1) <= stability_threshold:
                j += 1

            if j - i > best_stable_len:
                best_stable_len = j - i
                best_stable_start = i
                best_stable_end = j - 1

            i = j

        if best_stable_len >= stability_window:
            stable_start = best_stable_start
            stable_end = best_stable_end

    # Calculate mean of the stable period
    if stable_end - stable_start + 1 >= stability_window:
        return np.mean(values[stable_start:stable_end+1])

    return None

def get_filtered_stats(df, column, filter_zeros=True):
    """Calculate statistics for a column, optionally only considering non-zero GPU utilization periods"""
    if filter_zeros and 'GPUUtil(%)' in df.columns:
        filtered_df = df[df['GPUUtil(%)'] > 0]
        if len(filtered_df) == 0:  # If no data after filtering, use original data
            filtered_df = df
    else:
        filtered_df = df

    if column not in filtered_df.columns or filtered_df[column].isna().all():
        return None

    return (
        filtered_df[column].mean(),
        filtered_df[column].median(),
        filtered_df[column].min(),
        filtered_df[column].max()
    )

def get_stats_text(series, label, df=None, filter_zeros=True, unit=""):
    """Generate statistics text for a data series"""
    if series.isna().all():
        return f"{label}: No data"

    # If full DataFrame is provided, use filtered statistics
    if df is not None and filter_zeros:
        stats = get_filtered_stats(df, series.name, filter_zeros)
        if stats:
            mean, median, min_val, max_val = stats
        else:
            # If filtering fails, fall back to regular statistics
            mean = series.mean()
            median = series.median()
            min_val = series.min()
            max_val = series.max()
    else:
        # Use regular statistics
        mean = series.mean()
        median = series.median()
        min_val = series.min()
        max_val = series.max()

    # Calculate stable mean
    stable_mean = calculate_stable_mean(series.dropna().values)
    stable_mean_str = f", Stable Mean={stable_mean:.1f}" if stable_mean is not None else ""

    # Format text, put unit in parentheses
    unit_str = f" ({unit})" if unit else ""
    return (f"{label}{unit_str}: Median={median:.1f}, Min={min_val:.1f}, "
            f"Max={max_val:.1f}, Mean={mean:.1f}{stable_mean_str}")

def plot_nvsim_metrics(df, output_file=None, show=False, title_prefix="", comments=None):
    """Plot NVSIM metrics chart"""
    # Calculate relative time (seconds from the first data point)
    if 'Timestamp' in df.columns and not df['Timestamp'].isna().all():
        start_time = df['Timestamp'].iloc[0]
        df['relative_time'] = [(t - start_time).total_seconds() if t is not None else 0 for t in df['Timestamp']]
    else:
        df['relative_time'] = range(len(df))

    # Get product name and architecture for title
    product_name = df['ProductName'].iloc[0] if 'ProductName' in df.columns and not pd.isna(df['ProductName'].iloc[0]) else "Unknown GPU"
    architecture = df['Architecture'].iloc[0] if 'Architecture' in df.columns and not pd.isna(df['Architecture'].iloc[0]) else ""

    # Generate rich title
    rich_title = f"{product_name} ({architecture}) NVSIM Monitoring Metrics"
    if title_prefix:
        rich_title = f"{title_prefix} {rich_title}"

    # Create chart with 4 subplots
    fig, axes = plt.subplots(4, 1, figsize=(15, 16), sharex=True)
    fig.suptitle(rich_title, fontsize=16, y=0.98)

    # 1. Plot GPU and Memory Utilization
    axes[0].set_title('GPU and Memory Utilization (%)')

    print(f"DataFrame contains {len(df)} records")

    if 'GPUUtil(%)' in df.columns:
        axes[0].plot(df['relative_time'], df['GPUUtil(%)'], label='GPU Utilization', color='red')

        # Calculate stable mean and add reference line
        gpu_util_values = df[df['GPUUtil(%)'] > 0]['GPUUtil(%)'].values
        gpu_stable_mean = calculate_stable_mean(gpu_util_values)
        if gpu_stable_mean is not None:
            axes[0].axhline(y=gpu_stable_mean, linestyle='--', color='green', alpha=0.8)
            axes[0].text(0.01, gpu_stable_mean, f"{gpu_stable_mean:.1f}% (Stable Mean)",
                        verticalalignment='center', color='red', fontsize=11,
                        bbox=dict(facecolor='white', alpha=0.7, boxstyle='round,pad=0.2'))

    if 'MemUtil(%)' in df.columns:
        axes[0].plot(df['relative_time'], df['MemUtil(%)'], label='Memory Utilization', color='blue')

        # Calculate stable mean and add reference line
        mem_util_values = df[df['GPUUtil(%)'] > 0]['MemUtil(%)'].values
        mem_stable_mean = calculate_stable_mean(mem_util_values)
        if mem_stable_mean is not None:
            axes[0].axhline(y=mem_stable_mean, linestyle='--', color='green', alpha=0.8)
            axes[0].text(0.01, mem_stable_mean, f"{mem_stable_mean:.1f}% (Stable Mean)",
                        verticalalignment='center', color='blue', fontsize=11,
                        bbox=dict(facecolor='white', alpha=0.7, boxstyle='round,pad=0.2'))

    # Add statistics
    if 'GPUUtil(%)' in df.columns and 'MemUtil(%)' in df.columns:
        gpu_util_stats = get_stats_text(df['GPUUtil(%)'], "GPU", df, unit="%")
        mem_util_stats = get_stats_text(df['MemUtil(%)'], "Memory", df, unit="%")
        stats_text = f"{gpu_util_stats}\n{mem_util_stats}"
        axes[0].text(0.5, 0.08, stats_text, transform=axes[0].transAxes,
                    fontsize=11, verticalalignment='bottom', horizontalalignment='center',
                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))

    axes[0].set_ylabel('Utilization (%)')
    axes[0].legend(loc='upper right')
    axes[0].grid(False)

    # 2. Plot Power Metrics
    axes[1].set_title('Power Metrics (W)')
    if 'GPUAvgPower(W)' in df.columns:
        axes[1].plot(df['relative_time'], df['GPUAvgPower(W)'], label='GPU Average Power', color='red')

        # Calculate stable mean and add reference line
        power_values = df[df['GPUUtil(%)'] > 0]['GPUAvgPower(W)'].values
        power_stable_mean = calculate_stable_mean(power_values)
        if power_stable_mean is not None:
            axes[1].axhline(y=power_stable_mean, linestyle='--', color='green', alpha=0.8)
            axes[1].text(0.01, power_stable_mean, f"{power_stable_mean:.1f}W (Stable Mean)",
                        verticalalignment='center', color='red', fontsize=11,
                        bbox=dict(facecolor='white', alpha=0.7, boxstyle='round,pad=0.2'))

    if 'GPUInstPower(W)' in df.columns:
        axes[1].plot(df['relative_time'], df['GPUInstPower(W)'], label='GPU Instantaneous Power', color='pink', linestyle='--')

    if 'MemAvgPower(W)' in df.columns:
        axes[1].plot(df['relative_time'], df['MemAvgPower(W)'], label='Memory Average Power', color='blue')

        # Calculate stable mean and add reference line
        mem_power_values = df[df['GPUUtil(%)'] > 0]['MemAvgPower(W)'].values
        mem_power_stable_mean = calculate_stable_mean(mem_power_values)
        if mem_power_stable_mean is not None:
            axes[1].axhline(y=mem_power_stable_mean, linestyle='--', color='green', alpha=0.8)
            axes[1].text(0.01, mem_power_stable_mean, f"{mem_power_stable_mean:.1f}W (Stable Mean)",
                        verticalalignment='center', color='blue', fontsize=11,
                        bbox=dict(facecolor='white', alpha=0.7, boxstyle='round,pad=0.2'))

    # Add statistics
    power_stats = []
    if 'GPUAvgPower(W)' in df.columns:
        power_stats.append(get_stats_text(df['GPUAvgPower(W)'], "GPU Power", df, unit="W"))
    if 'MemAvgPower(W)' in df.columns:
        power_stats.append(get_stats_text(df['MemAvgPower(W)'], "Memory Power", df, unit="W"))

    if power_stats:
        stats_text = "\n".join(power_stats)
        axes[1].text(0.5, 0.08, stats_text, transform=axes[1].transAxes,
                    fontsize=11, verticalalignment='bottom', horizontalalignment='center',
                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))

    axes[1].set_ylabel('Power (W)')
    axes[1].legend(loc='upper right')
    axes[1].grid(False)

    # 3. Plot GPU and Memory Temperatures
    axes[2].set_title('GPU and Memory Temperatures (°C)')
    if 'GPUTemp(C)' in df.columns:
        axes[2].plot(df['relative_time'], df['GPUTemp(C)'], label='GPU Temperature', color='red')

        # Calculate stable mean and add reference line
        gpu_temp_values = df[df['GPUUtil(%)'] > 0]['GPUTemp(C)'].values
        gpu_temp_stable_mean = calculate_stable_mean(gpu_temp_values)
        if gpu_temp_stable_mean is not None:
            axes[2].axhline(y=gpu_temp_stable_mean, linestyle='--', color='green', alpha=0.8)
            axes[2].text(0.01, gpu_temp_stable_mean, f"{gpu_temp_stable_mean:.1f}°C (Stable Mean)",
                        verticalalignment='center', color='red', fontsize=11,
                        bbox=dict(facecolor='white', alpha=0.7, boxstyle='round,pad=0.2'))

    if 'MemTemp(C)' in df.columns:
        axes[2].plot(df['relative_time'], df['MemTemp(C)'], label='Memory Temperature', color='blue')

        # Calculate stable mean and add reference line
        mem_temp_values = df[df['GPUUtil(%)'] > 0]['MemTemp(C)'].values
        mem_temp_stable_mean = calculate_stable_mean(mem_temp_values)
        if mem_temp_stable_mean is not None:
            axes[2].axhline(y=mem_temp_stable_mean, linestyle='--', color='green', alpha=0.8)
            axes[2].text(0.01, mem_temp_stable_mean, f"{mem_temp_stable_mean:.1f}°C (Stable Mean)",
                        verticalalignment='center', color='blue', fontsize=11,
                        bbox=dict(facecolor='white', alpha=0.7, boxstyle='round,pad=0.2'))

    # Add statistics
    temp_stats = []
    if 'GPUTemp(C)' in df.columns:
        temp_stats.append(get_stats_text(df['GPUTemp(C)'], "GPU Temperature", df, unit="°C"))
    if 'MemTemp(C)' in df.columns:
        temp_stats.append(get_stats_text(df['MemTemp(C)'], "Memory Temperature", df, unit="°C"))

    if temp_stats:
        stats_text = "\n".join(temp_stats)
        axes[2].text(0.5, 0.08, stats_text, transform=axes[2].transAxes,
                    fontsize=11, verticalalignment='bottom', horizontalalignment='center',
                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))

    axes[2].set_ylabel('Temperature (°C)')
    axes[2].legend(loc='upper right')
    axes[2].grid(False)

    # 4. Plot SM Clock Frequency
    axes[3].set_title('SM Clock Frequency (MHz)')
    if 'SMClocks(MHz)' in df.columns:
        axes[3].plot(df['relative_time'], df['SMClocks(MHz)'], label='SM Clock', color='red')

        # Calculate stable mean and add reference line
        sm_freq_values = df[df['GPUUtil(%)'] > 0]['SMClocks(MHz)'].values
        sm_freq_stable_mean = calculate_stable_mean(sm_freq_values)
        if sm_freq_stable_mean is not None:
            axes[3].axhline(y=sm_freq_stable_mean, linestyle='--', color='green', alpha=0.8)
            axes[3].text(0.01, sm_freq_stable_mean, f"{sm_freq_stable_mean:.1f}MHz (Stable Mean)",
                        verticalalignment='center', color='red', fontsize=11,
                        bbox=dict(facecolor='white', alpha=0.7, boxstyle='round,pad=0.2'))

    # Add statistics for SM Clock only
    if 'SMClocks(MHz)' in df.columns:
        sm_freq_stats = get_stats_text(df['SMClocks(MHz)'], "SM Clock", df, unit="MHz")
        axes[3].text(0.5, 0.08, sm_freq_stats, transform=axes[3].transAxes,
                    fontsize=11, verticalalignment='bottom', horizontalalignment='center',
                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))

    axes[3].set_ylabel('Frequency (MHz)')
    axes[3].set_xlabel('Time')
    axes[3].legend(loc='upper right')
    axes[3].grid(False)

    # Beautify X axis
    from matplotlib.ticker import FuncFormatter, MultipleLocator

    for ax in axes:
        time_range = df['relative_time'].max() - df['relative_time'].min()

        if time_range < 1:
            ax.xaxis.set_major_locator(MultipleLocator(0.1))
        elif time_range < 10:
            ax.xaxis.set_major_locator(MultipleLocator(0.5))
        elif time_range < 60:
            ax.xaxis.set_major_locator(MultipleLocator(1))
        else:
            ax.xaxis.set_major_locator(MultipleLocator(5))

        ax.set_xticklabels([])
        ax.set_xlim(df['relative_time'].min(), df['relative_time'].max())

    axes[3].set_xlabel('Time')

    plt.tight_layout()
    plt.subplots_adjust(top=0.95)

    # Save or display chart
    if output_file:
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        print(f"Chart saved to: {output_file}")

    if show:
        plt.show()

    plt.close()

def crop_zero_utilization(df, margin=5, min_active_points=3):
    """
    Crop continuous periods of zero GPU utilization at beginning and end, keeping margin points.
    
    Args:
        df: DataFrame containing GPU utilization data
        margin: Number of points to keep around non-zero utilization as margin
        min_active_points: Minimum number of consecutive non-zero points required to be considered active
    
    Returns:
        DataFrame with zero utilization periods removed from beginning and end
    """
    if 'GPUUtil(%)' not in df.columns or len(df) <= margin*2:
        return df

    # Convert to numpy array for faster processing
    util_array = df['GPUUtil(%)'].fillna(0).values
    n = len(util_array)

    # Find regions with consecutive non-zero utilization
    active_regions = []
    i = 0
    while i < n:
        if util_array[i] > 0:
            start = i
            while i < n and util_array[i] > 0:
                i += 1
            end = i - 1
            # Only consider regions with sufficient consecutive non-zero points
            if end - start + 1 >= min_active_points:
                active_regions.append((start, end))
        else:
            i += 1

    # If no significant active regions found, return original data
    if not active_regions:
        return df

    # Find the largest active region
    largest_region = max(active_regions, key=lambda r: r[1] - r[0])

    # Add margin to the region
    start_idx = max(0, largest_region[0] - margin)
    end_idx = min(n - 1, largest_region[1] + margin)

    # Crop data
    cropped_df = df.iloc[start_idx:end_idx+1].reset_index(drop=True)

    return cropped_df

def downsample_gpu_data(df, threshold=200):
    """
    Downsample data when the number of points exceeds the threshold.
    For GPU utilization = 100% regions, keep only every other point.
    
    Args:
        df: DataFrame containing GPU data
        threshold: Maximum number of points before downsampling is applied
        
    Returns:
        Downsampled DataFrame
    """
    # Only downsample if we have more than threshold points
    if len(df) <= threshold or 'GPUUtil(%)' not in df.columns:
        return df

    indices_to_keep = []
    in_full_util = False
    skip_next = False

    for i in range(len(df)):
        gpu_util = df['GPUUtil(%)'].iloc[i]

        if gpu_util == 100.0:
            if not in_full_util:
                # Just entered full utilization region
                in_full_util = True
                skip_next = False

            # In full utilization region, keep every other point
            if not skip_next:
                indices_to_keep.append(i)
                skip_next = True
            else:
                skip_next = False
        else:
            # For non-100% points, keep all
            in_full_util = False
            indices_to_keep.append(i)

    downsampled_df = df.iloc[indices_to_keep].reset_index(drop=True)
    print(f"Downsampled data from {len(df)} to {len(downsampled_df)} points")

    return downsampled_df

def collect_statistics(df, csv_filename):
    """Collect statistics for each metric into a dictionary"""
    stats_dict = {'filename': os.path.basename(csv_filename)}

    with warnings.catch_warnings():
        warnings.simplefilter("ignore", category=RuntimeWarning)

        # Collect statistics for each metric
        for col in df.columns:
            if col not in ['Timestamp', 'relative_time', 'ProductName', 'Architecture', 'PerfState']:
                try:
                    # Get statistics
                    mean_val = df[col].mean()
                    median_val = df[col].median()
                    min_val = df[col].min()
                    max_val = df[col].max()

                    # Calculate stable mean
                    stable_mean = calculate_stable_mean(df[col].dropna().values)

                    stats_dict[f"{col}_mean"] = mean_val
                    stats_dict[f"{col}_median"] = median_val
                    stats_dict[f"{col}_min"] = min_val
                    stats_dict[f"{col}_max"] = max_val
                    if stable_mean is not None:
                        stats_dict[f"{col}_stable_mean"] = stable_mean
                except Exception as e:
                    print(f"  Error collecting statistics for {col}: {e}")

    return stats_dict

def process_csv_file(csv_path, output=None, show=False, title='', margin=10):
    """Process single CSV file and generate chart"""
    # If no output file specified, use the same directory as the input CSV with .png extension
    if not output and not show:
        base_name = os.path.splitext(os.path.basename(csv_path))[0]
        output_dir = os.path.dirname(csv_path)
        output = os.path.join(output_dir, f"{base_name}.png")

    # Read data
    df, comments = read_nvsim_metrics(csv_path)

    # Crop beginning and ending parts with zero GPU utilization
    original_length = len(df)
    if 'GPUUtil(%)' in df.columns:
        df = crop_zero_utilization(df, margin=margin)
        if len(df) < original_length:
            print(f"Data cropped from {original_length} to {len(df)} points, removed zero utilization periods")

    # Downsample data if there are too many points
    # df = downsample_gpu_data(df, threshold=200)

    # Output statistics
    print(f"Read {len(df)} records from {os.path.basename(csv_path)}")
    print("Statistics:")

    # Format and print column headers
    print("  {:<20} {:>10} {:>10} {:>10} {:>10} {:>15}".format(
        "Metric", "Mean", "Median", "Min", "Max", "Stable Mean"))
    print("  {:<20} {:>10} {:>10} {:>10} {:>10} {:>15}".format(
        "-" * 20, "-" * 10, "-" * 10, "-" * 10, "-" * 10, "-" * 15))

    # Collect statistics
    stats_dict = collect_statistics(df, csv_path)

    # Suppress warnings for mean calculation on empty slices
    with warnings.catch_warnings():
        warnings.simplefilter("ignore", category=RuntimeWarning)

        # Calculate and print useful statistics
        for col in df.columns:
            if col not in ['Timestamp', 'relative_time', 'ProductName', 'Architecture', 'PerfState']:
                try:
                    mean_val = df[col].mean()
                    median_val = df[col].median()
                    max_val = df[col].max()
                    min_val = df[col].min()

                    # Calculate stable mean
                    stable_mean = calculate_stable_mean(df[col].dropna().values)
                    stable_mean_str = f"{stable_mean:.2f}" if stable_mean is not None else "N/A"

                    # Print formatted statistics
                    print("  {:<20} {:>10.2f} {:>10.2f} {:>10.2f} {:>10.2f} {:>15}".format(
                        col, mean_val, median_val, min_val, max_val, stable_mean_str))
                except Exception as e:
                    print(f"  {col:<20} Error: {e}")

    # Plot chart
    plot_nvsim_metrics(df, output, show, title, comments)

    # Display metadata information
    if 'ProductName' in df.columns:
        print(f"\nGPU: {df['ProductName'].iloc[0]}")
    if 'Architecture' in df.columns:
        print(f"Architecture: {df['Architecture'].iloc[0]}")

    return output, stats_dict

def main():
    parser = argparse.ArgumentParser(description='Visualize NVSIM GPU Monitoring Data')
    parser.add_argument('input_path', help='CSV data file or folder containing CSV files')
    parser.add_argument('-o', '--output', help='Output image file path (only valid when processing a single file)')
    parser.add_argument('-s', '--show', action='store_true', help='Display chart')
    parser.add_argument('-t', '--title', default='', help='Chart title prefix')
    parser.add_argument('-m', '--margin', type=int, default=10,
                       help='Number of zero-utilization data points to keep as margin when cropping. Set to a large value (e.g., 999999) to avoid cropping')

    args = parser.parse_args()

    # Check if input path is a file or folder
    if os.path.isfile(args.input_path):
        # Process single file
        output_file, stats = process_csv_file(args.input_path, args.output, args.show, args.title, args.margin)

    elif os.path.isdir(args.input_path):
        # Process all CSV files in folder
        print(f"Scanning folder: {args.input_path}")
        csv_files = [f for f in os.listdir(args.input_path)
                    if f.lower().endswith('.csv')
                    and not f.startswith("nvsim_summary_")]

        if not csv_files:
            print("No CSV files found!")
            return

        print(f"Found {len(csv_files)} CSV files")
        all_stats = []

        for csv_file in csv_files:
            csv_path = os.path.join(args.input_path, csv_file)
            print(f"\nProcessing file: {csv_file}")
            try:
                output_file, stats = process_csv_file(csv_path, None, args.show, args.title, args.margin)
                if stats:
                    all_stats.append(stats)
            except Exception as e:
                print(f"Error processing {csv_file}: {e}")

    else:
        print(f"Error: Input path '{args.input_path}' does not exist!")

if __name__ == "__main__":
    main()
